{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "077c0ce6",
   "metadata": {},
   "source": [
    "\n",
    "# Árboles de decisión y Ensambles con datos de la EDA\n",
    "\n",
    "En este cuaderno se utiliza uno de los conjuntos de datos que se han trabajado en las EDA (por ejemplo `archive/Base.csv`) para entrenar y evaluar modelos de Árbol de Decisión y Bosque Aleatorio (RandomForest).\n",
    "\n",
    "El flujo general es:\n",
    "\n",
    "1. Cargar el dataset y explorar sus dimensiones.\n",
    "2. Preprocesar los datos: manejar valores nulos, codificar variables categóricas y normalizar las variables numéricas.\n",
    "3. Dividir los datos en conjuntos de entrenamiento y prueba.\n",
    "4. Entrenar un **DecisionTreeClassifier** y un **RandomForestClassifier**.\n",
    "5. Evaluar el desempeño de ambos modelos usando métricas de clasificación (accuracy, F1, matriz de confusión).\n",
    "6. Visualizar la importancia de las variables según el bosque aleatorio.\n",
    "7. Comparar resultados y discutir el ajuste, sesgo y varianza de los modelos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daab56c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Ruta del dataset de la EDA (ajusta según la estructura de tu repositorio)\n",
    "# Ejemplo: 'archive/Base.csv' debe existir cuando ejecutes el notebook.\n",
    "dataset_path = 'archive/Base.csv'\n",
    "\n",
    "# Cargar el dataset\n",
    "df = pd.read_csv(dataset_path)\n",
    "print('Forma del conjunto de datos:', df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8159def5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Eliminar filas con valores nulos\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "# Detectar la columna objetivo buscando palabras clave en el nombre\n",
    "possible_targets = [col for col in df.columns if any(key in col.lower() for key in ['fraud', 'fraude', 'target', 'objetivo'])]\n",
    "if possible_targets:\n",
    "    target_col = possible_targets[0]\n",
    "else:\n",
    "    # Si no se encuentra, utiliza la última columna como objetivo\n",
    "    target_col = df.columns[-1]\n",
    "\n",
    "print('Columna objetivo seleccionada:', target_col)\n",
    "\n",
    "# Separar características (X) y etiqueta (y)\n",
    "X = df.drop(columns=[target_col]).copy()\n",
    "y = df[target_col].copy()\n",
    "\n",
    "# Codificar variables categóricas\n",
    "cat_cols = X.select_dtypes(include=['object', 'category']).columns\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col])\n",
    "\n",
    "# Convertir a numpy arrays\n",
    "X_array = X.values\n",
    "y_array = y.values\n",
    "\n",
    "# Dividir en entrenamiento y prueba (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_array, y_array, test_size=0.2, random_state=42, stratify=y_array)\n",
    "\n",
    "print('Tamaño entrenamiento:', X_train.shape, 'Tamaño prueba:', X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e08c9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Entrenar Árbol de Decisión\n",
    "clf_tree = DecisionTreeClassifier(random_state=42)\n",
    "clf_tree.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones y métricas para el árbol\n",
    "y_pred_tree = clf_tree.predict(X_test)\n",
    "acc_tree = accuracy_score(y_test, y_pred_tree)\n",
    "f1_tree = f1_score(y_test, y_pred_tree, average='binary')\n",
    "cm_tree = confusion_matrix(y_test, y_pred_tree)\n",
    "\n",
    "print('Desempeño del Árbol de Decisión:')\n",
    "print('Accuracy:', acc_tree)\n",
    "print('F1-score:', f1_tree)\n",
    "print('Matriz de confusión:\n",
    "', cm_tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac413528",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Entrenar Bosque Aleatorio\n",
    "clf_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf_rf.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones y métricas para el bosque\n",
    "y_pred_rf = clf_rf.predict(X_test)\n",
    "acc_rf = accuracy_score(y_test, y_pred_rf)\n",
    "f1_rf = f1_score(y_test, y_pred_rf, average='binary')\n",
    "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "\n",
    "print('Desempeño del Bosque Aleatorio:')\n",
    "print('Accuracy:', acc_rf)\n",
    "print('F1-score:', f1_rf)\n",
    "print('Matriz de confusión:\n",
    "', cm_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cb6e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Importancia de características del Bosque Aleatorio\n",
    "importances = clf_rf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "top_features = X.columns[indices]\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.title('Importancia de características (RandomForest)')\n",
    "plt.bar(range(len(importances)), importances[indices], align='center')\n",
    "plt.xticks(range(len(importances)), top_features, rotation=90)\n",
    "plt.ylabel('Importancia')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420b9ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Comparar métricas en un DataFrame\n",
    "results = pd.DataFrame({\n",
    "    'Modelo': ['Árbol de Decisión', 'Bosque Aleatorio'],\n",
    "    'Accuracy': [acc_tree, acc_rf],\n",
    "    'F1-score': [f1_tree, f1_rf]\n",
    "})\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76daf9f",
   "metadata": {},
   "source": [
    "\n",
    "## Discusión sobre sesgo, varianza y ajuste\n",
    "\n",
    "* **Sesgo:** El árbol de decisión suele tener bajo sesgo pero puede sobreajustarse a los datos. El bosque aleatorio tiende a reducir el sesgo al promediar muchos árboles.\n",
    "* **Varianza:** Un solo árbol tiene alta varianza; el bosque aleatorio disminuye la varianza gracias al bagging y la selección aleatoria de características.\n",
    "* **Ajuste:** Si las métricas en entrenamiento y prueba son similares y altas, el modelo está bien ajustado. Si el rendimiento en entrenamiento es mucho mejor que en prueba, hay sobreajuste (overfitting). Un rendimiento bajo en ambos conjuntos indica subajuste (underfitting).\n",
    "\n",
    "Ajustando hiperparámetros como la profundidad máxima del árbol (`max_depth`) o el número de árboles (`n_estimators`) se puede mejorar el equilibrio entre sesgo y varianza.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
